{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6a95e03",
   "metadata": {},
   "source": [
    "# [Pytorch basic document]\n",
    "\n",
    "-----\n",
    "\n",
    "pytorch를 활용하여 만들 수 있는 model은 무궁무진하지만 기초를 알지 못한다면 원하는 모델을 만들기는 쉽지 않다\n",
    "\n",
    "해당 project에서는 pytorch의 기능과 함수들에 대해서 자세하게 보고 활용하여 활용 방법에 대해서 다루는 것을 목적으로 한다.\n",
    "\n",
    "- Python Version : Python 3.13.7\n",
    "\n",
    "참고 자료 : https://www.youtube.com/watch?v=kY14KfZQ1TI&list=PLCC34OHNcOtpcgR9LEYSdi9r7XIbpkpK1\n",
    "\n",
    "참고자료 : https://tutorials.pytorch.kr/beginner/blitz/tensor_tutorial.html\n",
    "\n",
    "-----\n",
    "\n",
    "## 목차(contents)\n",
    "\n",
    "- 1. Tensor (Tensor 생성, Tensor의 Attribution)\n",
    "- 2. Tensor Operations (Math)\n",
    "- 3. Neural Network (make, train, evaluate(using test, new data), save & load model)\n",
    "- 4. CNN(Convolution Neural Network) - Image fliter, Image kernel, Convolutional Layer & RGB, Pooling Layer, Train, Test, Checking Work\n",
    "\n",
    "+) 추가로 필요한 모델의 구현 case는 지속적으로 update 할 예정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19728f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (25.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (3.6)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (2025.12.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (3.6)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (2025.12.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.3.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.3.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pytorch install, numpy\n",
    "\n",
    "%pip install --upgrade pip\n",
    "%pip install torch\n",
    "%pip install --upgrade torch\n",
    "%pip install numpy\n",
    "%pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed338f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch 모델 import\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6029692d",
   "metadata": {},
   "source": [
    "# 1. Tensor란 무엇인가?\n",
    "---\n",
    "\n",
    "tensor(텐서)는 array나 matrix와 유사한 특수 자료구조로, pytorch에서는 tensor를 통해 model으로의 input과 output 뿐만 아닌 모델의 매개변수를 encoding하는 과정에 사용된다.\n",
    "\n",
    "tensor는 numpy의 ndarray와 유사하지만, GPU나 연산 가속을 위한 특수 하드웨어에서 실행 가능하다는 점이 다르다.\n",
    "\n",
    "---\n",
    "\n",
    "### Tensor의 종류\n",
    "\n",
    "|Dimension|tensor 종류|명칭|\n",
    "|:---:|:---:|:---:|\n",
    "|0 dimension tensor|zeroth-order-tenso|scalar|\n",
    "|1 dimension tensor|First-order-tensor|vector|\n",
    "|2 dimension tensor|Second-order-tensor|matrix|\n",
    "|3 dimension tensor|Third-order-tensor|tensor|\n",
    "|4 dimension tensor|Fourth-order-tensor|stack with 3 dimension tensor|\n",
    "|5 dimension tensor|Fifth-order-tensor|expand side with 4 dimension tensor|\n",
    "|...|...|...|\n",
    "\n",
    "![tensor의 종류](./tensor.png)\n",
    "\n",
    "참고자료 : https://tutorials.pytorch.kr/beginner/blitz/tensor_tutorial.html\n",
    "\n",
    "참고자료 : https://www.youtube.com/watch?v=2yBEZzQu8dA&list=PLCC34OHNcOtpcgR9LEYSdi9r7XIbpkpK1&index=2\n",
    "\n",
    "이미지 출처 : Pytorch로 시작하는 딥러닝 입문\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840bdbe5",
   "metadata": {},
   "source": [
    "## 1) Tensor 초기화 및 생성\n",
    "---\n",
    "\n",
    "tensor 생성 당시 자료형은 자동으로 유추하여 맞게 생성되기 때문에 따로 지정할 필요는 없다.\n",
    "\n",
    "크게 tensor의 생성 방법으로는 4가지로 나뉜다.\n",
    "\n",
    "1) data -> tensor\n",
    "2) data -> numpy array -> tensor\n",
    "3) original_tensor -> duplicate_tensor(attribute 유지 O)\n",
    "4) original_tensor -> duplicate_tensor(attribute 유지 X)\n",
    "5) data(zero, one, random) -> tensor\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "221a848d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# tensor 생성 (data -> tensor)\n",
    "\n",
    "data = [[1, 2],[3, 4]] # 데이터 배열 생성\n",
    "x_data = torch.tensor(data) # data를 tensor로 변환\n",
    "\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c2c9b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# tensor 생성 (data -> numpy array -> tensor)\n",
    "import numpy as np\n",
    "\n",
    "np_array = np.array(data) # numpy array 생성\n",
    "x_np = torch.from_numpy(np_array) # numpy array -> tensor로 변환\n",
    "\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60393171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor : \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor : \n",
      " tensor([[0.1086, 0.4773],\n",
      "        [0.5344, 0.8663]], dtype=torch.float64) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tensor 생성 (다른 tensor -> 새로운 tensor)\n",
    "# 속성의 유지여부에 따라 ones_like, rand_like를 나눠서 쓰는데 속성에는 tensor의 shape과 datatype이 해당된다.\n",
    "\n",
    "tensor_ones = torch.ones_like(x_data) # 기존 tensor의 속성을 유지\n",
    "tensor_rand = torch.rand_like(x_data, dtype=float) # 기존 tensor의 속성을 변경\n",
    "\n",
    "print(f\"Ones Tensor : \\n {tensor_ones} \\n\")\n",
    "print(f\"Random Tensor : \\n {tensor_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf057049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand_tensor \n",
      " tensor([[0.2019, 0.3528, 0.4042, 0.2899, 0.1571],\n",
      "        [0.9293, 0.3239, 0.7022, 0.9065, 0.8192],\n",
      "        [0.7025, 0.0715, 0.3640, 0.3029, 0.2898]]) \n",
      "\n",
      "ones_tensor \n",
      " tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]]) \n",
      "\n",
      "zeros_tensor \n",
      " tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tensor 생성을 random(랜덤값) 또는 constant(상수값)을 활용하여 생성하는 방법\n",
    "\n",
    "shape = (3, 5) #tensor의 차원을 column:3, row:5로 setting\n",
    "\n",
    "rand_tensor = torch.rand(shape) #랜덤값으로 shape에 맞게 tensor를 생성\n",
    "ones_tensor = torch.ones(shape) #모든 원소값은 1로 shape에 맞게 tensor 생성\n",
    "zeros_tensor = torch.zeros(shape) #모든 원소값을 0으로 shape에 맞게 tensor 생성\n",
    "\n",
    "# 각 tensor의 구조 및 원소의 상태를 print하여 확인\n",
    "print(f\"rand_tensor \\n {rand_tensor} \\n\")\n",
    "print(f\"ones_tensor \\n {ones_tensor} \\n\")\n",
    "print(f\"zeros_tensor \\n {zeros_tensor} \\n\")\n",
    "\n",
    "# numpy array를 기준으로 원소 값 초기화를 통해 tensor 생성도 가능함\n",
    "\n",
    "# torch.ones_like(t) # t와 같은 사이즈의 1로 채워진 tensor를 출력\n",
    "# torch.zeros_like(t) # 모든 값을 0으로 \n",
    "# torch.ones(size=[]) # 1로 채워진 size 차원의 tensor를 출력\n",
    "# torch.zeros(size=[]) # 0으로 채워진 size 차원의 tensor를 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd64175",
   "metadata": {},
   "source": [
    "## 2) Tensor의 Attribute(속성)\n",
    "\n",
    "---\n",
    "\n",
    "tensor의 attribute(속성)은 tensor의 shape, datatype 및 store device location을 의미한다.\n",
    "\n",
    "따라서, 각 tensor는 이런 attribute를 모두 가지고 있기 때문에 특정 tensor의 shape/dtype/device의 속성을 확인이 가능하다\n",
    "\n",
    "추가적인 속성 확인인 size(), dim()의 경우에는 메소드(함수)이기 때문에 (괄호)를 뺴먹지 않도록 주의해야 함.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a737136b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_sample \n",
      " tensor([[0.9656, 0.5045, 0.2803],\n",
      "        [0.5095, 0.9885, 0.3313]]) \n",
      "\n",
      "Shape of tensor : torch.Size([2, 3])\n",
      "Size of tensor : torch.Size([2, 3])\n",
      "Dimension of tensor : 2\n",
      "Datatype of tensor : torch.float32\n",
      "Device tensor is stored on : cpu\n"
     ]
    }
   ],
   "source": [
    "# tensor 랜덤값으로 생성\n",
    "\n",
    "tensor_sample = torch.rand(2, 3) #랜덤 값을 활용하여 생성한 2x3 tensor\n",
    "\n",
    "print(f\"tensor_sample \\n {tensor_sample} \\n\") #tensor_sample을 출력\n",
    "print(f\"Shape of tensor : {tensor_sample.shape}\") #tensor_sample의 shape을 출력\n",
    "print(f\"Size of tensor : {tensor_sample.size()}\") #tensor_sample의 size를 출력\n",
    "print(f\"Dimension of tensor : {tensor_sample.dim()}\") #tensor_sample의 dimension을 출력\n",
    "print(f\"Datatype of tensor : {tensor_sample.dtype}\") #tensor_sample의 데이터 타입을 출력\n",
    "print(f\"Device tensor is stored on : {tensor_sample.device}\") #tensor_sample이 저장된 device의 location을 출력\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101bd023",
   "metadata": {},
   "source": [
    "# 2. Tensor Operation(텐서 연산)\n",
    "\n",
    "---\n",
    "\n",
    "선형대수 연산 기능, 수학적 계산, 인덱싱, 슬라이싱, 임의 샘플링 등 tensor 구조로 연산 기능을 지원하는 pytorch에는 다양한 함수가 존재한다.\n",
    "\n",
    "가장 기본적인 Reshape, Slice 기법을 확인 후 수학적 tensor 연산인 Add, Subtract, Multiply, Divide, Remainders, Exponent, Shorthand, Longhand, Reassignment에 대해서 예시 코드를 통해 보도록 하겠다.\n",
    "\n",
    "추가적으로 필요하다고 생각되는 tensor operation에 대해서는 하단의 내용을 추가할 예정이다.\n",
    "\n",
    "Pytorch의 Tensor 연산 document : https://docs.pytorch.org/docs/stable/torch.html\n",
    "\n",
    "참고자료 : https://www.youtube.com/watch?v=Ta3z9vZaoMc&list=PLCC34OHNcOtpcgR9LEYSdi9r7XIbpkpK1&index=4\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbe2826",
   "metadata": {},
   "source": [
    "### 0) tensor 생성 함수 정리\n",
    "\n",
    "| 자료형(category) | dtype | 설명 | 대표 생성 함수 | dtype 지정 예시 |\n",
    "|------------------|--------|--------|---------------------|-----------------------|\n",
    "| **부호 없는 정수** | `torch.uint8` | Unsigned 8-bit | `torch.UInt8Tensor()` | `dtype=torch.uint8` |\n",
    "| **정수** | `torch.int8` | Signed 8-bit | `torch.Int8Tensor()` | `dtype=torch.int8` |\n",
    "| | `torch.int16` (`torch.short`) | 16-bit | `torch.ShortTensor()` | `dtype=torch.int16` |\n",
    "| | `torch.int32` (`torch.int`) | 32-bit | `torch.IntTensor()` | `dtype=torch.int32` |\n",
    "| | `torch.int64` (`torch.long`) | 64-bit (가장 많이 사용) | `torch.LongTensor()` | `dtype=torch.int64` |\n",
    "| **부동소수점(Float)** | `torch.float16` (`torch.half`) | Half precision (16-bit) | `torch.HalfTensor()` | `dtype=torch.float16` |\n",
    "| | `torch.float32` (`torch.float`) | Single precision (32-bit) | `torch.FloatTensor()` | `dtype=torch.float32` |\n",
    "| | `torch.float64` (`torch.double`) | Double precision (64-bit) | `torch.DoubleTensor()` | `dtype=torch.float64` |\n",
    "| **Boolean** | `torch.bool` | True/False | `torch.BoolTensor()` | `dtype=torch.bool` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84dc261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor 생성\n",
    "\n",
    "tensor_a = torch.tensor([1, 2, 3, 4])\n",
    "tensor_b = torch.tensor([5, 6, 7, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf45366",
   "metadata": {},
   "source": [
    "### 1) Tensor addition (덧셈)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7716de0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  8, 10, 12])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor addition\n",
    "\n",
    "tensor_a + tensor_b\n",
    "\n",
    "# another way to write addition\n",
    "\n",
    "tensor_a.add(tensor_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f450667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  8, 10, 12])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor addition longhead(일반적) version\n",
    "\n",
    "torch.add(tensor_a, tensor_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc22383a",
   "metadata": {},
   "source": [
    "### 2) tensor subtraction (뻴셈)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5315156d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 4, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subtraction\n",
    "\n",
    "tensor_b - tensor_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de37786d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 4, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subtraction function\n",
    "\n",
    "torch.sub(tensor_b, tensor_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632e77fa",
   "metadata": {},
   "source": [
    "### 3) tensor multiplication (곱셈)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "297fa9d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 12, 21, 32])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiplication\n",
    "\n",
    "tensor_a * tensor_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90f9e99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 12, 21, 32])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiplication longhand\n",
    "\n",
    "torch.mul(tensor_a, tensor_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc70a88",
   "metadata": {},
   "source": [
    "### 4) tensor division (나눗셈)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94cba3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.0000, 3.0000, 2.3333, 2.0000])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# division\n",
    "\n",
    "tensor_b / tensor_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b44fb408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2000, 0.3333, 0.4286, 0.5000])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# division longhand\n",
    "\n",
    "torch.div(tensor_a, tensor_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a774e3a5",
   "metadata": {},
   "source": [
    "### 5) tensor reminder modulus (나머지 연산)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a117470f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reminder modulus(나머지)\n",
    "\n",
    "tensor_b % tensor_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc4db785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remainder longhand (나머지)\n",
    "\n",
    "torch.remainder(tensor_b, tensor_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8579d86",
   "metadata": {},
   "source": [
    "### 6) tensor exponents/power (지수와 제곱근) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "990aee48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    1,    64,  2187, 65536])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exponents / power (제곱)\n",
    "\n",
    "torch.pow(tensor_a, tensor_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0974ca0f",
   "metadata": {},
   "source": [
    "### 7) reassignment (기존 tensor 값 재할당)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8240e974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 14, 17, 20])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reassignment\n",
    "\n",
    "tensor_a + tensor_b\n",
    "\n",
    "tensor_a = tensor_a + tensor_b\n",
    "\n",
    "tensor_a.add_(tensor_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924bd262",
   "metadata": {},
   "source": [
    "### 8) 추가적인 tensor 속성들 (내적 곱셈, 원소별 곱셈, 형태 변환, cat, stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "353074e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 생성\n",
    "data_1 = [[1, 3, 4], [5, 6, 7], [9, 10, 11]]\n",
    "data_2 = [[11, 13, 14], [15, 16, 17], [19, 110, 111]]\n",
    "\n",
    "# numpy array로 변환\n",
    "t1 = np.array(data_1)\n",
    "t2 = np.array(data_2)\n",
    "\n",
    "# numpy array -> tensor로 변환\n",
    "tensor_1 = torch.FloatTensor(t1)\n",
    "tensor_2 = torch.FloatTensor(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43b82cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(36.2222)\n",
      "tensor(326.)\n",
      "tensor(111.)\n",
      "tensor(8)\n"
     ]
    }
   ],
   "source": [
    "# tensor의 세부 속성 (mean, sum, max, argmax)\n",
    "\n",
    "print(tensor_2.mean()) #tensor 원소의 전체값 평균\n",
    "print(tensor_2.sum()) #tensor 원소의 전체값의 합 (dim=0)을 달면 차원제거 가능\n",
    "print(tensor_2.max()) #tensor 원소 중 가장 큰 값 (dim=0)을 달면 차원제거 가능\n",
    "print(tensor_2.argmax()) #tensor의 모든 원소 중 가장 큰 값의 index 출력 (dim=0)을 탈면 차원제거 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47ff9868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Multiplication result : \n",
      "tensor([[ 132.,  501.,  509.],\n",
      "        [ 278.,  931.,  949.],\n",
      "        [ 458., 1487., 1517.]])\n",
      "\n",
      "element-wise Multiplication : \n",
      "tensor([[  11.,   39.,   56.],\n",
      "        [  75.,   96.,  119.],\n",
      "        [ 171., 1100., 1221.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tensor의 내적 곱셈 및 원소별 곱셈\n",
    "\n",
    "result1 = tensor_1.matmul(tensor_2)\n",
    "result2 = tensor_1.mul(tensor_2)\n",
    "\n",
    "print(f\"Matrix Multiplication result : \\n{result1}\\n\")\n",
    "print(f\"element-wise Multiplication : \\n{result2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f8135d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  3.,  4.],\n",
      "        [ 5.,  6.,  7.],\n",
      "        [ 9., 10., 11.]])\n",
      "tensor([[ 1.,  3.,  4.],\n",
      "        [ 5.,  6.,  7.],\n",
      "        [ 9., 10., 11.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  3.,  4.]],\n",
       "\n",
       "        [[ 5.,  6.,  7.]],\n",
       "\n",
       "        [[ 9., 10., 11.]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor의 형태 변형 및 변환 (view(), squeeze(), unsqueeze())\n",
    "\n",
    "reshape_tensor = tensor_1.view([3, 3]) #tensor의 형태 변경(numpy의 reshape 기능)\n",
    "print(reshape_tensor)\n",
    "\n",
    "reshape_tensor.squeeze(1) #tensor의 차원을 제거\n",
    "print(reshape_tensor)\n",
    "\n",
    "reshape_tensor.unsqueeze(dim=1) #tensor의 차원을 특정 위치에 차원을 추가함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1464fdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1.,   3.,   4.],\n",
      "        [  5.,   6.,   7.],\n",
      "        [  9.,  10.,  11.],\n",
      "        [ 11.,  13.,  14.],\n",
      "        [ 15.,  16.,  17.],\n",
      "        [ 19., 110., 111.]])\n",
      "tensor([[[  1.,   3.,   4.],\n",
      "         [  5.,   6.,   7.],\n",
      "         [  9.,  10.,  11.]],\n",
      "\n",
      "        [[ 11.,  13.,  14.],\n",
      "         [ 15.,  16.,  17.],\n",
      "         [ 19., 110., 111.]]])\n"
     ]
    }
   ],
   "source": [
    "# tensor 병합(cat()), 연결(stack())\n",
    "\n",
    "new_tensor = torch.cat([tensor_1, tensor_2], dim=0) #tensor 병합하여 하나의 tensor 생성\n",
    "new_stack_tensor = torch.stack([tensor_1, tensor_2], dim=0) #tensor를 연결 - 병합하지 않고 연결만 진행함\n",
    "\n",
    "print(new_tensor)\n",
    "print(new_stack_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd783aa",
   "metadata": {},
   "source": [
    "# 3. Neural Network Model (인공 신경망 모델)\n",
    "\n",
    "신경망 모델은 인간의 뇌 신경망 구조를 기반으로 구현하여 만든 컴퓨터 모델을 의미하며, 상호 연결된 node들이 계층적으로 데이터를 처리하며 학습하는 모델을 의미한다\n",
    "\n",
    "하단의 이미지는 가장 기본적인 Neural Network를 표현한 자료로서, 데이터를 처음에 모델에 input으로 전달하면 input_layer를 통해서 값이 전달되고 각 노드간의\n",
    "\n",
    "가중치값을 조정 후 활성화 함수를 통과하며 마지막에는 예측값 또는 결과값을 출력한다. 순서) input_layer -> hidden_layer -> output_layer\n",
    "\n",
    "![neural network image](./neural_network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6533a8",
   "metadata": {},
   "source": [
    "## 1) 신경망 구축 및 데이터 전처리 진행\n",
    "\n",
    "신경망 구축 후 학습, 검증, 실제 데이터를 통한 예측의 과정에 사용할 데이터는 Iris small classic dataset을 사용하였다.\n",
    "\n",
    "Data 출처 : https://archive.ics.uci.edu/dataset/53/iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4185e3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network 구현을 위한 라이브러리 import 진행\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12234533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 구조를 담은 클래스를 생성\n",
    "\n",
    "class Model(nn.Module):\n",
    "    # Input Layer (4) -> Hidden Layer 1 -> Hidden Layer 2 -> Hidden Layer 3 -> Output Layer 1의 구조로 신경망을 구성한다.\n",
    "    def __init__(self, in_features = 4, h1 = 8, h2 = 9, h3 = 8, out_features = 3): # 학습시킬 데이터의 특성이 4개이기 때문에 features는 4로 지정\n",
    "        super().__init__() #nn.module을 객체화 진행\n",
    "        self.fc1 = nn.Linear(in_features, h1) #각 Layer 별로 노드들 간의 연결 관계를 지정하여 Fully-Connected-Layer의 구조로 만들어줌\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.fc3 = nn.Linear(h2, h3)\n",
    "        self.out = nn.Linear(h3, out_features)\n",
    "        \n",
    "    def forward(self, x): # 순전파 함수 선언\n",
    "        x = F.relu(self.fc1(x)) #relu 활성화 함수 적용\n",
    "        x = F.relu(self.fc2(x)) #relu 활성화 함수 적용\n",
    "        x = F.relu(self.fc3(x)) #relu 활성화 함수 적용\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x # 신경망 학습 후 결과물 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02670241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 만든 신경망에 데이터를 넣어서 학습을 진행\n",
    "\n",
    "# 시드겂을 지정\n",
    "torch.manual_seed(41)\n",
    "\n",
    "# 모델을 지정\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd5bf00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/leemac/Library/Python/3.13/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/leemac/Library/Python/3.13/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/leemac/Library/Python/3.13/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/leemac/Library/Python/3.13/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.24.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn) (2.3.5)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.24.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn) (2.3.5)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 필요 라이브러리 설치 및 import 진행\n",
    "\n",
    "%pip install pandas\n",
    "%pip install --upgrade pandas\n",
    "%pip install scikit-learn\n",
    "%pip install --upgrade scikit-learn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e9e0cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils._bunch.Bunch"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습시킬 iris 데이터 sklearn 라이브러리 내부에서 호출\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "type(iris)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10ece490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iris 데이터셋의 key값 확인\n",
    "\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "972d53e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "  variety  \n",
       "0  setosa  \n",
       "1  setosa  \n",
       "2  setosa  \n",
       "3  setosa  \n",
       "4  setosa  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원하는 데이터값만 뽑아서 데이터 프레임으로 생성\n",
    "\n",
    "my_df = pd.DataFrame(iris['data'], columns=iris['feature_names']) #dataframe의 구성을 특징 이름을 열로, 데이터 값들을 행으로 지정\n",
    "my_df['target'] = iris['target'] # iris 데이터셋의 target 데이터를 my_df에 추가\n",
    "my_df['variety'] = my_df['target'].apply(lambda idx : iris['target_names'][idx]) # iris target 인덱스 값에 맞는 target 이름을 따로 열에 인덱싱 진행\n",
    "my_df = my_df.drop(columns=['target']) # target 데이터 열을 모두 삭제\n",
    "\n",
    "my_df.head() # my_df의 윗부분 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b85c6ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/pw50z6011qq_vscwb8z4rldh0000gn/T/ipykernel_2357/3482883565.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  my_df['variety'] = my_df['variety'].replace('virginica', 2.0) # virginica -> 2.0 으로 변경\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     variety  \n",
       "0        0.0  \n",
       "1        0.0  \n",
       "2        0.0  \n",
       "3        0.0  \n",
       "4        0.0  \n",
       "..       ...  \n",
       "145      2.0  \n",
       "146      2.0  \n",
       "147      2.0  \n",
       "148      2.0  \n",
       "149      2.0  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variety 열에 해당하는 데이터를 string -> integer로 변경\n",
    "\n",
    "my_df['variety'] = my_df['variety'].replace('setosa', 0.0) # setosa -> 0.0 으로 변경\n",
    "my_df['variety'] = my_df['variety'].replace('versicolor', 1.0) # versicolor -> 1.0 으로 변경\n",
    "my_df['variety'] = my_df['variety'].replace('virginica', 2.0) # virginica -> 2.0 으로 변경\n",
    "\n",
    "# 변경 후 dataframe 확인\n",
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "66c761b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     variety  \n",
       "0        0.0  \n",
       "1        0.0  \n",
       "2        0.0  \n",
       "3        0.0  \n",
       "4        0.0  \n",
       "..       ...  \n",
       "145      2.0  \n",
       "146      2.0  \n",
       "147      2.0  \n",
       "148      2.0  \n",
       "149      2.0  \n",
       "\n",
       "[150 rows x 5 columns]>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7f66a7",
   "metadata": {},
   "source": [
    "## 2) 훈련데이터, 검증데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a435d533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Dataset과 Test Dataset으로 split 진행\n",
    "\n",
    "X = my_df.drop('variety', axis=1) # X에는 variety 열 제외 모든 데이터값 저장\n",
    "Y = my_df['variety'] # Y에는 variety 열 데이터만 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab0e9d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X와 Y 데이터를 numpy array로 변경\n",
    "\n",
    "X = X.values\n",
    "Y = Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1741ff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #훈련,테스트 데이터 분할 함수 import\n",
    "\n",
    "# Train Data와 Test Data로 분리 진행 (Test Data : 80%, Train Data : 20%)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc651500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 모델로 input이 가능하도록 데이터를 float tensor 형태로 변환\n",
    "\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40e1810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variety 값이 들어있는 Y 데이터들은 tensor long 형태로 변환\n",
    "\n",
    "Y_train = torch.LongTensor(Y_train)\n",
    "Y_test = torch.LongTensor(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9454429d",
   "metadata": {},
   "source": [
    "## 3) 손실함수, 최적화모델, 모델 학습 진행(forward propagation), 학습 후 모델 loss값 그래프 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "91106118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수의 손실값을 줄이기 위한 손실함수와 최적화 함수 및 Learning rate 지정\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() #CrossEntropyLoss함수 사용\n",
    "optimize = torch.optim.Adam(model.parameters(), lr=0.01) #손실 함수와 Learning rate 값 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d3a60a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Model(\n",
       "  (fc1): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (fc2): Linear(in_features=8, out_features=9, bias=True)\n",
       "  (fc3): Linear(in_features=9, out_features=8, bias=True)\n",
       "  (out): Linear(in_features=8, out_features=3, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 신경망 모델의 구조 확인\n",
    "\n",
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a70a60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 and loss: 1.1371241807937622\n",
      "Epoch: 10 and loss: 0.9740466475486755\n",
      "Epoch: 20 and loss: 0.7153900265693665\n",
      "Epoch: 30 and loss: 0.5231950283050537\n",
      "Epoch: 40 and loss: 0.3444252610206604\n",
      "Epoch: 50 and loss: 0.1814032644033432\n",
      "Epoch: 60 and loss: 0.06792421638965607\n",
      "Epoch: 70 and loss: 0.03545410931110382\n",
      "Epoch: 80 and loss: 0.025035256519913673\n",
      "Epoch: 90 and loss: 0.020947806537151337\n"
     ]
    }
   ],
   "source": [
    "# 모델에 데이터를 전달하여 학습 진행 (epoch는 데이터 전체를 활용하여 모델을 학습시키는 횟수를 의미한다)\n",
    "\n",
    "epochs = 100 #학습 반복 횟수 지정 1000번으로\n",
    "losses = [] #각 epoch별 loss값을 리스트에 저장\n",
    "\n",
    "for i in range(epochs):\n",
    "    # 순전파 진행 및 예측 \n",
    "    y_pred = model.forward(X_train)\n",
    "    \n",
    "    # loss값 계산\n",
    "    loss = criterion(y_pred, Y_train)\n",
    "    # loss값을 매 epoch마다 losses에 저장\n",
    "    losses.append(loss.detach().numpy())\n",
    "    \n",
    "    # epoch 10 마다 loss값 상태 출력\n",
    "    if i % 10 == 0:\n",
    "        print(f'Epoch: {i} and loss: {loss}')\n",
    "    \n",
    "    # 매 epoch마다 순전파를 통한 학습의 결과인 loss값을 기반으로 역전파(back propagation)을 진행하여 노드간의 가중치값을 fine turning 진행\n",
    "    optimize.zero_grad()\n",
    "    loss.backward() #역전파\n",
    "    optimize.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ee2ebdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loss값을 활용하여 그래프를 통해 값의 변화 추이를 확인\n",
    "\n",
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel(\"loss/error\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e578dc1a",
   "metadata": {},
   "source": [
    "## 4) 학습 완료된 모델을 Test Dataset을 통해 검증 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b5746526",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(): #역전파를 차단 (검증을 위한 setting)\n",
    "    Y_eval = model.forward(X_test) \n",
    "    loss = criterion(Y_eval, Y_test) # loss값이나 에러값을 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "264574e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2032)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss #loss값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8b0c37ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.) tensor([-6.3215,  1.5852,  7.4445]) \t Virginica \t 2 \n",
      "2.) tensor([-7.7888,  1.0691,  9.5685]) \t Virginica \t 2 \n",
      "3.) tensor([-8.4323,  1.0829, 10.3727]) \t Virginica \t 2 \n",
      "4.) tensor([-1.5514,  7.8292, -1.9418]) \t Versicolor \t 1 \n",
      "5.) tensor([-7.6306,  1.0838,  9.3636]) \t Virginica \t 2 \n",
      "6.) tensor([ 1.8196, 10.7156, -7.8281]) \t Versicolor \t 1 \n",
      "7.) tensor([-5.3013,  3.3475,  5.2069]) \t Virginica \t 2 \n",
      "8.) tensor([-1.3084,  8.2797, -2.4920]) \t Versicolor \t 1 \n",
      "9.) tensor([-6.5362,  2.1708,  7.4007]) \t Virginica \t 2 \n",
      "10.) tensor([-8.2276,  1.0935, 10.1135]) \t Virginica \t 2 \n",
      "11.) tensor([-5.0607,  3.6324,  4.7496]) \t Virginica \t 2 \n",
      "12.) tensor([ 25.6046,  16.1169, -42.1762]) \t Setosa \t 0 \n",
      "13.) tensor([ 23.1665,  14.6048, -38.1524]) \t Setosa \t 0 \n",
      "14.) tensor([ 2.9214,  9.8389, -8.8181]) \t Versicolor \t 1 \n",
      "15.) tensor([ 22.2065,  14.8905, -36.9821]) \t Setosa \t 0 \n",
      "16.) tensor([-4.5401,  4.2594,  3.7560]) \t Virginica \t 1 \n",
      "17.) tensor([ 22.9309,  14.7961, -37.8979]) \t Setosa \t 0 \n",
      "18.) tensor([-6.0657,  2.1507,  6.8174]) \t Versicolor \t 2 \n",
      "19.) tensor([ 26.7660,  16.5477, -43.9794]) \t Setosa \t 0 \n",
      "20.) tensor([ 20.6279,  13.4025, -34.1096]) \t Setosa \t 0 \n",
      "21.) tensor([ 2.2558, 10.1571, -8.1058]) \t Versicolor \t 1 \n",
      "22.) tensor([-8.0252,  1.0620,  9.8662]) \t Virginica \t 2 \n",
      "23.) tensor([ 22.7303,  14.9868, -37.7283]) \t Setosa \t 0 \n",
      "24.) tensor([ 24.8597,  15.5125, -40.8901]) \t Setosa \t 0 \n",
      "25.) tensor([ 3.1575, 10.7618, -9.6206]) \t Versicolor \t 1 \n",
      "26.) tensor([ 1.5362, 10.1008, -7.1292]) \t Versicolor \t 1 \n",
      "27.) tensor([-1.7875,  7.8709, -1.6659]) \t Versicolor \t 1 \n",
      "28.) tensor([ 1.7915, 10.3269, -7.5842]) \t Versicolor \t 1 \n",
      "29.) tensor([ 25.5724,  16.0070, -42.0873]) \t Setosa \t 0 \n",
      "30.) tensor([-2.3024,  6.8666, -0.4749]) \t Versicolor \t 1 \n",
      "We got 28 correct!\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(X_test):\n",
    "        Y_val = model.forward(data)\n",
    "        \n",
    "        # Y_test 데이트 즉 모델의 예측 결과를 인덱스값에 맞는 꽃의 이름으로 저장\n",
    "        if Y_test[i] == 0:\n",
    "            x = \"Setosa\"\n",
    "        elif Y_test[i] == 1:\n",
    "            x = \"Versicolor\"\n",
    "        else:\n",
    "            x = \"Virginica\"\n",
    "        \n",
    "        #모델이 생각하는 데이터의 예측값을 출력\n",
    "        print(f\"{i+1}.) {str(Y_val)} \\t {x} \\t {Y_val.argmax().item() } \")\n",
    "        \n",
    "        # 모델이 검증 데이터를 정답으로 맞춘 경우 correct에 +1\n",
    "        if Y_val.argmax().item() == Y_test[i]:\n",
    "            correct +=1\n",
    "        \n",
    "# 총 correct 결과값 출력\n",
    "print(f\"We got {correct} correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e7611a",
   "metadata": {},
   "source": [
    "## 5) 학습 완료된 모델을 저장하고, 사전 학습 모델 불러오는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2537cbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 저장\n",
    "\n",
    "torch.save(model.state_dict(), \"pretrained_model_prototype\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "943cf7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사전 훈련된 모델을 불러와 정의\n",
    "\n",
    "new_model = Model()\n",
    "new_model.load_state_dict(torch.load(\"pretrained_model_prototype\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e6347836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (fc1): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (fc2): Linear(in_features=8, out_features=9, bias=True)\n",
       "  (fc3): Linear(in_features=9, out_features=8, bias=True)\n",
       "  (out): Linear(in_features=8, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사전 훈련된 모델의 구조 확인\n",
    "\n",
    "new_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d8164f",
   "metadata": {},
   "source": [
    "# 4. CNN(Convolution Neural Network) - Using MNIST Dataset\n",
    "\n",
    "### Image fliter, Image kernel, Convolutional Layer & RGB, Pooling Layer, Train, Test, Checking Work\n",
    "\n",
    "CNN 모델은 Convolution Neural Network 합성곱 신경망으로 이미지, 비디오와 같은 vision data를 분석하는 딥러닝 알고리즘으로\n",
    "\n",
    "합성곱과 풀링 연산을 반복하는 신경망의 구조를 활용하여 이미지나 비디오의 특징을 추출하고 이를 분류하는 방식으로 사용된다.\n",
    "\n",
    "대표적인 CNN 모델로는 LeNet -> AlexNet -> VGGNet -> ResNet, DenseNet, EfficientNet의 순서로 발전하면서 많이 사용되고 있다.\n",
    "\n",
    "활용의 예시로는 Image classification, Object detection, Face recognition, Medical image analysis(X-ray, ), Natural Language Processing, Voice recognition 등이 있다.\n",
    "\n",
    "\n",
    "\n",
    "![convolution neural network image](./cnn_image.webp)\n",
    "\n",
    "- CNN Structure\n",
    "\n",
    "[input image -> Featured maps -> pooled featured maps -> featured maps -> pooled featured maps -> flatten layer -> fully connected layer -> output]\n",
    "\n",
    "[이미지 출처 : https://mijeongban.medium.com/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-cnn-convolutional-neural-networks-%EC%89%BD%EA%B2%8C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-836869f88375]\n",
    "\n",
    "CNN의 구조는 코드를 통해 조금 더 자세하게 보도록 하겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7561912a",
   "metadata": {},
   "source": [
    "## 1) MNIST Dataset에 대하여\n",
    "\n",
    "앞으로 DL이나 ML과 같이 어떤 인공지능 모델을 만들더라도 가장 중요한 것은 \"데이터를 자세하게 파악\"하는 것이다.\n",
    "\n",
    "MNIST 데이터셋의 경우 2차원 흑백의 수기로 작성된 숫자들을 작성한 이미지를 모아둔 dataset으로 28x28 크기의 2차원 행렬로 구성되어 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7bcb4f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
